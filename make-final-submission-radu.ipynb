{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007612,
     "end_time": "2020-11-29T20:58:32.244865",
     "exception": false,
     "start_time": "2020-11-29T20:58:32.237253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Idea\n",
    "* write your inference as python scripts so that each time it should clear the cache and reset the state\n",
    "* submit sample submission to pass through initial commit\n",
    "* run all inference codes for whole test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T20:58:32.267374Z",
     "iopub.status.busy": "2020-11-29T20:58:32.266404Z",
     "iopub.status.idle": "2020-11-29T20:58:32.269423Z",
     "shell.execute_reply": "2020-11-29T20:58:32.268912Z"
    },
    "papermill": {
     "duration": 0.015767,
     "end_time": "2020-11-29T20:58:32.269543",
     "exception": false,
     "start_time": "2020-11-29T20:58:32.253776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install -q --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T20:58:32.289151Z",
     "iopub.status.busy": "2020-11-29T20:58:32.288211Z",
     "iopub.status.idle": "2020-11-29T20:59:46.640092Z",
     "shell.execute_reply": "2020-11-29T20:59:46.639404Z"
    },
    "papermill": {
     "duration": 74.363374,
     "end_time": "2020-11-29T20:59:46.640230",
     "exception": false,
     "start_time": "2020-11-29T20:58:32.276856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pytorch16gpu/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==1.6.0cu101) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.6.0cu101) (1.18.5)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.6.0\r\n",
      "    Uninstalling torch-1.6.0:\r\n",
      "      Successfully uninstalled torch-1.6.0\r\n",
      "Successfully installed torch-1.6.0+cu101\r\n"
     ]
    }
   ],
   "source": [
    "! pip install ../input/pytorch16gpu/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T20:59:46.669809Z",
     "iopub.status.busy": "2020-11-29T20:59:46.667980Z",
     "iopub.status.idle": "2020-11-29T21:00:15.233429Z",
     "shell.execute_reply": "2020-11-29T21:00:15.231886Z"
    },
    "papermill": {
     "duration": 28.583508,
     "end_time": "2020-11-29T21:00:15.233581",
     "exception": false,
     "start_time": "2020-11-29T20:59:46.650073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/iterative-stratification/iterative_stratification-0.1.6-py3-none-any.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.23.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.18.5)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (0.14.1)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/iterative-stratification/iterative_stratification-0.1.6-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-29T21:00:15.261636Z",
     "iopub.status.busy": "2020-11-29T21:00:15.260844Z",
     "iopub.status.idle": "2020-11-29T21:00:15.263245Z",
     "shell.execute_reply": "2020-11-29T21:00:15.263845Z"
    },
    "papermill": {
     "duration": 0.018581,
     "end_time": "2020-11-29T21:00:15.263969",
     "exception": false,
     "start_time": "2020-11-29T21:00:15.245388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T21:00:15.306657Z",
     "iopub.status.busy": "2020-11-29T21:00:15.298980Z",
     "iopub.status.idle": "2020-11-29T21:19:46.831813Z",
     "shell.execute_reply": "2020-11-29T21:19:46.830641Z"
    },
    "papermill": {
     "duration": 1171.55719,
     "end_time": "2020-11-29T21:19:46.831957",
     "exception": false,
     "start_time": "2020-11-29T21:00:15.274767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_comp_GENES 463 n_comp_CELLS 60 total 523\r\n",
      "(23814, 876)\r\n",
      "(3982, 876)\r\n",
      "(21948, 875)\r\n",
      "(21948, 207)\r\n",
      "(3624, 875)\r\n",
      "(21948, 886)\r\n",
      "(21948, 4)\r\n",
      "871\r\n",
      "(21948, 1409)\r\n",
      "(21948, 4)\r\n",
      "(21948, 1012)\r\n",
      "(21948, 1016)\r\n",
      "(21948, 1223)\r\n",
      "(21948, 1224)\r\n",
      "(3624, 1016)\r\n",
      "(21948, 207)\r\n",
      "(3982, 207)\r\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.4862005329299448\r\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.025945434666105677\r\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023942074886914612\r\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01995704844594002\r\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.022067266691854034\r\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018885100153940064\r\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02082906274691872\r\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018486906854169708\r\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020227339631621388\r\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018550227848546846\r\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02011859327878641\r\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01814536303281784\r\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02010039819161529\r\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.018274643112506185\r\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020112419150013855\r\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01827875024506024\r\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020139492035883923\r\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018115134271127837\r\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020084464787573055\r\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01814877422792571\r\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020122764497131542\r\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01797566403235708\r\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020019248438378174\r\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017970447268869195\r\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019879632238028706\r\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018173057692391532\r\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019813522898956486\r\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017823197825678757\r\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019641947581608227\r\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017806555330753326\r\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01946976130315359\r\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01788935690586056\r\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019230705092026703\r\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.017684061106826576\r\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.018939107804950596\r\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01779269501566887\r\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.018652448754595673\r\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.017597086488136224\r\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01825192964811256\r\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01764627154916525\r\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01774259270641251\r\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.017691129259765147\r\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01719923587380976\r\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.017632331140339373\r\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016632935558648212\r\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.017669988396976675\r\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016249685204061476\r\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.017672933638095856\r\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016053722240030766\r\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.017691734938749246\r\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.48481778803187003\r\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.024992130749991962\r\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.024209249157296574\r\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01930719113775662\r\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02210413306897533\r\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018077081388660838\r\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.021079235440255074\r\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017753034430955137\r\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.020467050670497658\r\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01859079083161695\r\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02035185165595317\r\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01758687709059034\r\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.02032536920160055\r\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017389854256595883\r\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.02032283528883388\r\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01747801024466753\r\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020292673543419525\r\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017542773777885098\r\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020288774365748184\r\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01747702530452183\r\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.02023008697922679\r\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01732384863176516\r\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020128925627880337\r\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017398136188941343\r\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020048605521088062\r\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01725742955292974\r\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01983426599020975\r\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01734346297702619\r\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019828088163141754\r\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017198895955724377\r\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019663064592126488\r\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017072656750679018\r\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019445794729003006\r\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016953301403139318\r\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019155860271142876\r\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01686691769531795\r\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.018888691291752933\r\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016929523700049947\r\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01843523599234396\r\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.017019984046263353\r\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01800079662622749\r\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01684852974223239\r\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.017521216554324263\r\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01682546149407114\r\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01693715857665824\r\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016839869027691228\r\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016527729581339634\r\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01685362248016255\r\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016327465654931206\r\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01689573545008898\r\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.4869273282369993\r\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.026498456778270858\r\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02399919482532644\r\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019534719203199657\r\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.021839004825719082\r\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018590551029358592\r\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020675890433200953\r\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018927274750811712\r\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020257915880014427\r\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018353948582495963\r\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020053090853956495\r\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01839100109147174\r\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02002464078475524\r\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018127333000302316\r\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020035877973385102\r\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01785338108560869\r\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02002529923661347\r\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01820695328393153\r\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020076535846086315\r\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018273616582155226\r\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019999168582097458\r\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01810964314000947\r\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019927887110053187\r\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018054041053567615\r\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01988724252059512\r\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01815053022333554\r\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019756588445854012\r\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01804658320865461\r\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019675012446776795\r\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018080999702215196\r\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019443996740083624\r\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017889566746141228\r\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01919720714816647\r\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01783597142036472\r\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.018914566681224064\r\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.0177404808146613\r\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01861288433853727\r\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017804625337677342\r\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01825537475464988\r\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.017831428215972014\r\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.017708135068579746\r\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.017707643365221366\r\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.017200132260901214\r\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017653151601552963\r\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016616928731057332\r\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01770831402391195\r\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016230129099784107\r\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.017702619891081538\r\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016024605996471687\r\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01770438368299178\r\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.48576042998283014\r\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.026195446561489786\r\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02405917946330822\r\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01938679050654173\r\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02185380575756957\r\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018314133930419172\r\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.020611406351528028\r\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018258625907557353\r\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020137668158994974\r\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01790317930281162\r\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.02007588880123013\r\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017796497366258077\r\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020024032909830992\r\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01832170036754438\r\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020034170104530607\r\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01798483112028667\r\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020077915984566194\r\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.018365594079451902\r\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020095356692471644\r\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01800733722214188\r\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02002328683207505\r\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017901407022561346\r\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020007459460383785\r\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017769661199833666\r\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019890491735108578\r\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017751358875206538\r\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019815557860653765\r\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01750680303999356\r\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019641360200017038\r\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017563853705567973\r\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01949351381537688\r\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01749027581619365\r\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019264323514525908\r\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017570619178669793\r\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.019019497320545416\r\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017391059627490383\r\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.018721925414228527\r\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01739284350935902\r\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018259979777690703\r\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01728326305747032\r\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01772670285354783\r\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.0172465730458498\r\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01721666662199219\r\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.0173706074112228\r\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016695896924956002\r\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017394963518849442\r\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016238441459671425\r\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01739219818264246\r\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016041656622975846\r\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017409821173974445\r\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.48673417508278205\r\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.026597408468232435\r\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02399340478460426\r\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019319100634140128\r\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021824203188652577\r\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018315296346212134\r\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.020797998927857563\r\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017903681707513684\r\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02027255770466898\r\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018152662881595248\r\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020085035958259865\r\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018041817772695246\r\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020071174773941006\r\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017842444262522107\r\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020122481132115143\r\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.018038659082616076\r\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02009837113428807\r\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017702571883359376\r\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.0200887323235688\r\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017877533703165895\r\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020009686954427456\r\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01797308334532906\r\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019913183133779228\r\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01771441677256542\r\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019930916838347912\r\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017916246317327023\r\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019744737883624824\r\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017815475708202404\r\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019721032430728275\r\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01789348602623624\r\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019480934663527252\r\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.0177632988540127\r\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01926853689972473\r\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017642756951425004\r\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.019012215479776478\r\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017674057771835255\r\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.018631007110673017\r\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017564321785946104\r\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018194535193775875\r\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01749418382806813\r\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01771445971225267\r\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017568365095511955\r\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.017195761365735012\r\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01753966280204408\r\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01664789642571755\r\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01757450514089535\r\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016166698464286932\r\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01761724816306549\r\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01597996810586124\r\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.017601950888467187\r\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.48661891643659794\r\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02616943685071809\r\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.024057642138306645\r\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01970180640263217\r\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021802244437993435\r\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01918782533279487\r\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.020731281772579834\r\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01846824660897255\r\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02031947874828525\r\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018203356808849745\r\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02018899911933619\r\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018694280886224338\r\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020187873622753483\r\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01832133989248957\r\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02013329027787499\r\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018277987358825548\r\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.02017295062272013\r\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018026566239339965\r\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.02012256503213143\r\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.018036424049309323\r\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020052638863199863\r\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018111314571329525\r\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019989644082776016\r\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01845944332224982\r\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019964842287742573\r\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018112015777400563\r\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019894134199273758\r\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01783479582518339\r\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01963454530155961\r\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.018082688163433756\r\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.0195798273873178\r\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017868514891181672\r\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01932474061090877\r\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01781629856143679\r\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01905136042530986\r\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.017622831942779676\r\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.01872005344004087\r\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01764580639345305\r\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.018327264115214348\r\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01754021817552192\r\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.017883224075363167\r\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.017620207050016948\r\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01741150360338498\r\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.017531693992870193\r\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016830390373217888\r\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.017645957853112904\r\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01647214231121799\r\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.017593194118567874\r\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01625135262240318\r\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.017614076951784748\r\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.48396911790621455\r\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.02559823031936373\r\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.024201695631811584\r\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.018798644840717315\r\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022082653112601543\r\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.020470890189920155\r\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.02099418610442376\r\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01759709492325783\r\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02043989987746961\r\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017397203216595308\r\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.0203813461964761\r\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017548795736261776\r\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.02029909228609092\r\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.0173670733081443\r\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.02030054240932931\r\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01749117685747998\r\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020307700838083805\r\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017434446274169853\r\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020229241864728756\r\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017553256691566536\r\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020209050872295662\r\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017200574624751296\r\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020138529534249203\r\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017718669931803432\r\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02003251699109872\r\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017461788867201122\r\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01989440162382696\r\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017098834312387876\r\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019823933465649254\r\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.0170888644776174\r\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.0196384461056711\r\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017050564262483803\r\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01948337880489619\r\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017011191163744246\r\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019147825791783955\r\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01694548199219363\r\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.018824135007309742\r\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01680771902735744\r\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018489961755340515\r\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016836135435317243\r\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01803808281387108\r\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016784222557076386\r\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.017452621778500252\r\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.0167439714340227\r\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016957247838971838\r\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01680274571159056\r\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01656114498315298\r\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016840669752231665\r\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016380193407066923\r\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016812434419989586\r\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.4870277437225093\r\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.02682110033929348\r\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.024087339435724445\r\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01945201227707522\r\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.021707071671194404\r\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018738791080457822\r\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020778027397111383\r\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01812069873724665\r\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02012881385094493\r\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.0183372898293393\r\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02006944646909289\r\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01851877367922238\r\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020058074136720085\r\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018499229475855826\r\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020069877936565964\r\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018244365922042302\r\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02005973848493865\r\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017965709710759777\r\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020048531995963875\r\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018052222153970173\r\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.019994643360485127\r\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018432511016726494\r\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01995835313233581\r\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018075594811567237\r\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019883503063316762\r\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017995700586055006\r\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019768579135628513\r\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018298483852829252\r\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019654114927797423\r\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018075075559318067\r\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019413293917139952\r\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01796780609126602\r\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019267638682992787\r\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017881244474223682\r\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.018993378147809176\r\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017685575570378986\r\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.018610357313695616\r\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017747507563659122\r\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01828633100610145\r\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.017589348421565124\r\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.017787881521847997\r\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01772004823599543\r\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01723708746016678\r\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017750993450837475\r\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016739794209490726\r\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.017663523767675673\r\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.01635103794426596\r\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.017662235988037928\r\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016133357322074635\r\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01767447234264442\r\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.48694437160326615\r\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.02593119250876563\r\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.024121906961837823\r\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020085881943149225\r\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.0217655697551957\r\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018524538592568467\r\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.020717980802385478\r\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017903059029153415\r\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.0201827833687302\r\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01794102819902556\r\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020010218010657894\r\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017842456432325498\r\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020043461617544618\r\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01784439624420234\r\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.02007623396161264\r\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017914192830877643\r\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.0200730597287634\r\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017748941454504216\r\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020082946322912718\r\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017915855667420797\r\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02000459410032652\r\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017949703522026537\r\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020025880109981027\r\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01778313549501555\r\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019944917179480957\r\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01782725958951882\r\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.01985115306383937\r\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017511538974940778\r\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019644324157903664\r\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017749226598867348\r\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019475337498596985\r\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017563392700893538\r\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019206803305632007\r\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017521130692745957\r\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.018955499708761266\r\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01739133774702038\r\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.018665383902996997\r\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01754096318036318\r\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01818437015732927\r\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.017424972594848702\r\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01769748565326207\r\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017340675980917045\r\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.017142974125751612\r\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017398694264037267\r\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016595324487799275\r\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017437222520155567\r\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016151089255228963\r\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017448376358619757\r\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015940214826786606\r\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01743443842445101\r\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.48621590407160314\r\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.026177186847609633\r\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.024017383641414883\r\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01961020418607137\r\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021964740345551483\r\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01830130026620977\r\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.020755382227724876\r\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01852046659983256\r\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02021216977711605\r\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018403766074163073\r\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.02012093496117471\r\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01777925599804696\r\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02010858069727386\r\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.018273749854415655\r\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020105851071792236\r\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017717073726303437\r\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02016810102361268\r\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018243116436197478\r\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020141548463615818\r\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017777388805852216\r\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020082072422340298\r\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01844651991611018\r\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019998777914198414\r\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.0183818436720792\r\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01992776792874371\r\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017765411449705854\r\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01984656421278698\r\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017868845942704117\r\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01967398380941671\r\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.0178180703181116\r\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01945121756390385\r\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017583858221769333\r\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019286226832132408\r\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017582009902552646\r\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01898939142246609\r\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01754020425655386\r\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.018675016725192898\r\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01744529856916736\r\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018271933302985155\r\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017493246944949907\r\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01773980427938311\r\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01749899219173719\r\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01723853444032695\r\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017394134226967308\r\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01668680881730456\r\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.017439951846266493\r\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01623459313523726\r\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01744734772535808\r\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01603968575110902\r\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.017448440878925955\r\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.4840920363971289\r\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.025990303925105502\r\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023941064307439155\r\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019695637162242617\r\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021928937984225544\r\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018660565093159675\r\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02062882870381725\r\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.019893214106559753\r\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020415920008351837\r\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01825441616986479\r\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020106492577579575\r\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018196708389690945\r\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02015820317024338\r\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01825988207544599\r\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02014144848816205\r\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.018248403923852102\r\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.02011038098430288\r\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018264293963355677\r\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020162366533085056\r\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01811552553304604\r\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020059038695973763\r\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01819100986633982\r\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019970447405416897\r\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01815206232879843\r\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019976195487855137\r\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01809623528804098\r\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019766019319818504\r\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018003575024860247\r\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01964056176011977\r\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01783867363951036\r\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01950698792664469\r\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01779213882982731\r\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019245926493211933\r\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.0177142184227705\r\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019013234265688538\r\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.017779120723051683\r\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.018725763844407124\r\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.017633689301354543\r\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.018269443843999634\r\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.017670835182070733\r\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01782421798755725\r\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.017627487783985478\r\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.017304271142389895\r\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.017684705103082315\r\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016778905005396708\r\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01762075565223183\r\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016325277019886\r\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01765778200434787\r\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01614982021999532\r\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01769657786935568\r\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.48573019062641304\r\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.027588631691677228\r\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.024278450811254806\r\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01891528767134462\r\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022004737208286922\r\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.0177248286615525\r\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.020934292088276234\r\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017814489879778454\r\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02039670995504096\r\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018290109799376557\r\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02033195369269537\r\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017472848083291734\r\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020273090826104515\r\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017555161193013192\r\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020321815990019535\r\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017686628736555576\r\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020368264407675335\r\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017579930940909046\r\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020306160525027393\r\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017460775401975426\r\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020259501736449158\r\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017472588643431663\r\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020180583040675392\r\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017282952554523945\r\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020057420813195084\r\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01730159678097282\r\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01994342524288357\r\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01715532567884241\r\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019854049900195736\r\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01734212919005326\r\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019702134073536465\r\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017247169890574048\r\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01948825075574543\r\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016990069672465323\r\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01925655704099631\r\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016928016420985972\r\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.018928807917172493\r\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01703844882015671\r\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018488359813025032\r\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016850310058466027\r\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01805650087856296\r\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01683413577931268\r\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.017572501977986616\r\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016850876994431017\r\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01707442839751425\r\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016823592675583702\r\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016647535578712173\r\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016901171925876823\r\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01647118737489201\r\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016894383249538285\r\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.48676287049740335\r\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.027587305435112546\r\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02399258546694352\r\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019278458718742644\r\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02167140034428478\r\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018927795439958574\r\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020728449711073054\r\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018664973282388277\r\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020110520608995083\r\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018072759147201266\r\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02007908395824641\r\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01807046008429357\r\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01996409627914864\r\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018305958328502518\r\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020112828385547128\r\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018227899074554445\r\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020045462873404044\r\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018743541464209555\r\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020069214862084735\r\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01833584452314036\r\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.02004748314999751\r\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018101429087775095\r\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019982091497874607\r\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01810625908630235\r\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01992260176606857\r\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018056753437433924\r\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019768283763614884\r\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.018104273666228566\r\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019707070704359207\r\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01804141617779221\r\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01947438487116873\r\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01792769974895886\r\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01926295742066237\r\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017863294056483677\r\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.018988030153686983\r\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017847777370895657\r\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.018644557422856346\r\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017637080273457936\r\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.018295610072023242\r\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.017710961108761174\r\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.017813635779286387\r\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01770786235907248\r\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.017315735564614736\r\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017657779290207794\r\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01682066831085151\r\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.017715158286903586\r\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.01641069379138903\r\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01777302763823952\r\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016218120082669013\r\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.017710645789546627\r\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.4865418729936554\r\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.02582573177559035\r\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023867153542211455\r\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019583924939589843\r\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02173345292626071\r\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01874479917543275\r\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.020578379912750563\r\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01797830986657313\r\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020113380394712853\r\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018217506472553525\r\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020059489597478053\r\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01809266632688897\r\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020087359418725446\r\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01779337807425431\r\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020061751378931268\r\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01803653868181365\r\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020084256387866328\r\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.018035687798900264\r\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020060211270503753\r\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017900105778660094\r\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020006201794221454\r\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017787356062659194\r\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020042385987556765\r\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017934108445686953\r\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019824079217484396\r\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01779997990067516\r\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019760461605704615\r\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017717357299157552\r\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01961122707457003\r\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01759059987962246\r\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019452175179863498\r\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01763908320239612\r\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019192516559014355\r\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017521225953740734\r\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01891306940003903\r\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017542699671217372\r\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.018585363810841183\r\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01742085282291685\r\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01818246897445978\r\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01744828016630241\r\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.017713479031502766\r\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017446168698370457\r\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.0171450625860343\r\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017360063908355577\r\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01659603800325498\r\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017399242706596853\r\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016169408322685826\r\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017428500152059965\r\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015910075413212724\r\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017438137770763466\r\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4858334189064909\r\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.02790166180142585\r\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02424348692369202\r\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01984418572529274\r\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021961966893919136\r\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018612180562580332\r\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.020726849392488384\r\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017928238711593783\r\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02021818099192519\r\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018049411037388968\r\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020164029632249603\r\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017999848843935656\r\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020161761456857556\r\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017984786673503762\r\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.0201432921829215\r\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017950038781718296\r\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020169624127447605\r\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017848620766445118\r\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020182331700039947\r\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018072788767954883\r\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.02014825760346392\r\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.018098948030349088\r\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020051219055186146\r\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017824702841394088\r\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019976515754841377\r\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.018009704921175453\r\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019863121063057064\r\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01777743296149899\r\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019696810930643394\r\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01775713842910002\r\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019507352856622227\r\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01766371406505213\r\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019264687487072704\r\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01759380880085861\r\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.018986237512064585\r\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017504593905280617\r\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.018725452958133774\r\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.017530722379246178\r\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018270004223492266\r\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017519904519705212\r\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01779892900283786\r\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017509272787719965\r\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.017238186618340187\r\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017535118194406524\r\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016661030618284924\r\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01759122172370553\r\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016264429363165644\r\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.017538376563393018\r\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016060251067729965\r\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01758105480386054\r\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.48628306419899064\r\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.026125620837722505\r\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.024107171141582985\r\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019496138659971102\r\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021788006256995857\r\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018662761098572185\r\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.020801730265004047\r\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018393700197339057\r\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020349112015379513\r\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.019132194827709878\r\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02018450355778138\r\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018154160332466876\r\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02016964390118053\r\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.018165053586874688\r\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02018235001605058\r\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01823520005813667\r\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.02017243225397407\r\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018147298267909458\r\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020170862260072128\r\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01823933752519744\r\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.0201420439677178\r\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018057893056954655\r\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.019956715796412765\r\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01808059649275882\r\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.019948832663720932\r\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018118781250502383\r\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019850466967276905\r\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017879277308072362\r\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019696472185677376\r\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.0178411387439285\r\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019538007717093697\r\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017708343560142177\r\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01930941083886917\r\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01779446051056896\r\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019088225533672863\r\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01766373219766787\r\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.018700464831098267\r\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0176997891494206\r\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01832659895518336\r\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.0175765369619642\r\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.017872485602139564\r\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.017593368887901306\r\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01734184283439232\r\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.017606459983757563\r\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016824740774767553\r\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.017667853459715843\r\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016497055190088955\r\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.017660762316414287\r\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016212547069712393\r\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.017675680560725077\r\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4861586376538743\r\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.027202604711055754\r\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.0243330046777492\r\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019462509346859797\r\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.0220738697419132\r\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01767022487308298\r\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.021068806233613388\r\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01819618535893304\r\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02037220819434826\r\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017583586222359112\r\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02033259888328072\r\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01726801480565752\r\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020261889242607613\r\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017476900666952132\r\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020307212379639564\r\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01779507494398526\r\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02028865245697291\r\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01752738774354969\r\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.02021691952224659\r\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017615923817668643\r\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.0202661017090946\r\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017195817455649375\r\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.02026334136346544\r\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017348316232008592\r\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02008603800736044\r\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01731774868177516\r\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020019979486106964\r\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01744041397635426\r\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.019792618661902954\r\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017217025426881655\r\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019729723654471447\r\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017176188555146965\r\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01954801349590222\r\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017242212566946233\r\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01922015926760176\r\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016964399069547654\r\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.018936577509494797\r\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016821537858673505\r\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018469861364397017\r\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01684177222528628\r\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.018033117643031088\r\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016761269180902413\r\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.017569171669690506\r\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016772755874054773\r\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.017092430559189423\r\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01674223041960171\r\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01665593995510236\r\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016763305930154664\r\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016485097892312468\r\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016781748378915447\r\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.48851520990966446\r\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.02718497562621321\r\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.024275028343944655\r\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.0196805118982281\r\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.021835485935537486\r\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.020661431178450585\r\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02077792016585378\r\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018169057582105907\r\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020243222872814992\r\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018705988143171582\r\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02007506718437602\r\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018472835049033166\r\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02013210422039902\r\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018392589049679893\r\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020089390123412557\r\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018277044381414143\r\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020040973341160447\r\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.018190737547619\r\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.02004242237031895\r\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01808360708611352\r\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020055989306556048\r\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.018350305195365634\r\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.02000616516673217\r\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018244097541485513\r\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019931210680817164\r\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.018244026015911782\r\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019802526278543647\r\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01797162177307265\r\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019693025476197258\r\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.018029643701655523\r\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019515364587198207\r\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01805909520813397\r\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019336579884164526\r\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017962141627711908\r\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019027470019612\r\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01784497613885573\r\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.018668810768991056\r\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017673822173050472\r\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01833684478689284\r\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01768467841403825\r\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.017861615485736053\r\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.017667302010314804\r\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01736616557396024\r\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.017702870203980377\r\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01686684561580637\r\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.017674986672188555\r\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016475188797407777\r\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01767775435000658\r\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016278209015183204\r\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.017652361440871442\r\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.4873741947277619\r\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.025841659626790456\r\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023795635147142585\r\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.019515771046280862\r\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02193968860011031\r\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.019129400035100323\r\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02058415526836893\r\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018174092790910177\r\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020132053833808342\r\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.018280084537608283\r\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020088772935262563\r\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01809265102658953\r\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.02009977718448117\r\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.018008519655891828\r\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020115603482092383\r\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01785288556878056\r\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020083983775472988\r\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01817802536700453\r\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020107750638122975\r\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01798156768615757\r\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02009451662591339\r\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01799738976572241\r\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01995003812123824\r\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0177325503634555\r\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019923574875795495\r\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01781180285449539\r\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.0198137758938718\r\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017643557755010468\r\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019620328094728672\r\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017775981979710715\r\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01947096255301994\r\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017569313091891154\r\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019209134807116793\r\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017633003741502763\r\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01895051529753382\r\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01742595567234925\r\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.018620620304922553\r\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01739447239254202\r\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018189094824730044\r\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01745045581566436\r\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01767566943554765\r\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01732138850327049\r\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01712930027096376\r\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.017398992766227042\r\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01659777269012084\r\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017427232888128075\r\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.01613353554458514\r\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017429911558117184\r\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01592443461944587\r\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017418563924729825\r\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4851700971307962\r\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.027204026139396077\r\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.0245119319634809\r\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019496630329419586\r\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02200455569486687\r\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018664409570834217\r\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02082768476743629\r\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01812058859778678\r\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.020282304251863472\r\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018679286846343207\r\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020101972963606964\r\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.018021088148302892\r\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020164976125933987\r\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01815093867480755\r\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02009860613801773\r\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017930630484924596\r\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02014883445656818\r\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.018203873050344342\r\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02015777522077163\r\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.018061426194275126\r\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020113762495094452\r\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017789889620069194\r\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020047794217648712\r\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017963287037085083\r\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.020006759362160297\r\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017730584669419947\r\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019865342388874378\r\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01795699315912583\r\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019671331024796204\r\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01765066262005883\r\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01955152402861395\r\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017697573584668776\r\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01930424219429277\r\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017632798209567282\r\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.019036675992327324\r\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017660762073800844\r\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.018743928373399853\r\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01759817369063111\r\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018316365818938484\r\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01749948368353002\r\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01784365578972991\r\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017489443313987815\r\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.017292366646554157\r\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017512702081790742\r\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016768524801169617\r\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01752405410961193\r\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01638452809277004\r\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.017520402256837663\r\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01616252549127608\r\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.017512097680831656\r\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.48476371563215187\r\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.025600721846733773\r\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023816769497226113\r\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01976350796009813\r\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021832875664467396\r\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018865686761481423\r\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.020775730775642223\r\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018366137519478798\r\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020137940142033756\r\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.018261907302907537\r\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020091946263784084\r\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.018583803623914718\r\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02019215870540643\r\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01810739380972726\r\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020131633535999317\r\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01844225259763854\r\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020159808864844017\r\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.018086364173463414\r\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020151857597132523\r\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01795233256582703\r\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020162160305873207\r\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.018018843020711627\r\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01996679674240126\r\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.018149624126298086\r\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01992989350380241\r\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.018132998953972544\r\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.019862909153427765\r\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.018059700301715307\r\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01960596920031568\r\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017788811373923505\r\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019480766242612964\r\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01777844133653811\r\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01931787174249041\r\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01768200168652194\r\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01896909829499065\r\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.017679031752049924\r\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.018633059630899326\r\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01762755055512701\r\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01828550342200459\r\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01758053159075124\r\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.017825094173135964\r\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.017520526450659546\r\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.017317089414143044\r\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01750318950840405\r\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016800406085246283\r\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.017587361963731903\r\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016329696233235838\r\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.017588114365935326\r\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016132243908941746\r\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01761874383581536\r\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4852209018165435\r\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.025865094895873752\r\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02419861389890961\r\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01975439132324287\r\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02220468518688627\r\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.017721646412142685\r\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.020851628854870796\r\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01776062814252717\r\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.02042223194587058\r\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01731246675231627\r\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020310493510054504\r\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017394789095435823\r\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020282765566978767\r\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01771163586527109\r\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020260659127455692\r\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017918111916099277\r\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.02019982901064382\r\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017325067546750818\r\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.02020653360185848\r\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017556271169866834\r\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.02020473537993604\r\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01740127032888787\r\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020054145513669304\r\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017334241260375294\r\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02008835053530292\r\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017389968463352747\r\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.019958664366192577\r\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017396373993584086\r\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01984992411419533\r\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017085235299808637\r\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019644296566105408\r\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017122772495661465\r\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019434040992696217\r\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017055159647549903\r\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01914040584360128\r\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.017074653559497426\r\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01880936528407577\r\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016878487169742586\r\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01837222557514906\r\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.017019894772342274\r\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.017906793960086678\r\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01689191950219018\r\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01738651536837004\r\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01688187729035105\r\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01680158912136719\r\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016950580424496105\r\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01636188139167169\r\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016873753549797196\r\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016140214747924736\r\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016863838476794107\r\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.48613451285301335\r\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.0262419266892331\r\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.024136921594830326\r\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01951797263962882\r\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.021743055908893145\r\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018777373379894664\r\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.02070222433357343\r\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018057599317814622\r\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020167946162885125\r\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.018089164687054498\r\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020095010213281986\r\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.018177907594612668\r\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02002583320395355\r\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.018044510031385082\r\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.02001614173887855\r\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.018331534468701907\r\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.02002748122343617\r\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01828468798526696\r\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020034679639948545\r\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.018414878472685813\r\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.02002047404755641\r\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01828639821282455\r\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.019936173284140817\r\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.018229924302015987\r\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.019891601586102568\r\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017929556619908128\r\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.019744882468868345\r\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.0178130925233875\r\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01959006110355802\r\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017925271391868593\r\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.0193555272272686\r\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017862950398453644\r\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01918606415227817\r\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017966360252882754\r\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.018931951183472236\r\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017710930854082107\r\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.018536270766036353\r\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.017679090771291938\r\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01818821021783961\r\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.017737023239689214\r\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.017691610285835546\r\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.017733502334782054\r\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01717485866788095\r\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01770630122295448\r\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016611515326819717\r\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01778966433235577\r\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016217144817984017\r\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.017775077984801362\r\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.015969559523093438\r\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.017778958646314486\r\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.4863310702226675\r\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.025866154155560903\r\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.024117478964863902\r\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01973093327667032\r\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02173329003318383\r\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018731180844562396\r\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02062048795667008\r\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018273567434932504\r\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020180942857787557\r\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01786342106227364\r\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01996871824954113\r\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017971761178757463\r\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020054651641823948\r\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01792896097259862\r\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020108671627775597\r\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01797881945967674\r\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.02007538422833394\r\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017953476362994738\r\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020047938084080272\r\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017915751678603035\r\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01996726525036523\r\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01746791196720941\r\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.019900201377968718\r\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017644120806029864\r\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.019881603722698496\r\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017834540669407165\r\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.019814881638888896\r\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017650572316987172\r\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019639725599737062\r\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017604607476719786\r\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019421810760115184\r\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017608128621109893\r\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019184419824095973\r\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01738551767276866\r\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.018954781720238012\r\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017583239477659975\r\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.018585238714505285\r\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01740944159350225\r\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018157988412808763\r\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01745723451354674\r\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01765899413204106\r\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.017431609971182687\r\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01710620770625172\r\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01742980969803674\r\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01651325023114464\r\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.017431831306644847\r\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.01605912809171816\r\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.017466074042022228\r\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.015861426541296235\r\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.017489411256143023\r\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4840155397474334\r\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.026312372537658495\r\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02422339351766783\r\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01953670913901399\r\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021801722789372223\r\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01841979002689614\r\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02062971019388541\r\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01844285981839194\r\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02020566412450179\r\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.018065474270021215\r\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020127245009053444\r\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.0179907316889833\r\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020178690741675488\r\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017881038872634664\r\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020104680007890514\r\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01816271645400454\r\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020146501034606194\r\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01838174325359218\r\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020122238367364025\r\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017853194053339606\r\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020068541776550854\r\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017947345040738583\r\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.019987223818358303\r\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.018058191108352998\r\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.019940615429178528\r\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017894447151133242\r\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.019812171792854435\r\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01789271700031617\r\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019628361299418022\r\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017869418815654868\r\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01948826688517263\r\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017488609862459058\r\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019285234730636727\r\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01750411284977899\r\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01899091460728559\r\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.017551567597205147\r\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.018648365026582844\r\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01757366525228409\r\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01821803845519173\r\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.017529523465782404\r\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.017724146762781817\r\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.017549608039724475\r\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.017184521496781836\r\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.017616095952689648\r\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016677083002160423\r\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.0175720701158485\r\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016246462409533022\r\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.017565048381905344\r\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016025119292401316\r\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01758781773969531\r\n",
      "CV log_loss:  0.01702051244961574\r\n",
      "\u001b[0m/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold2_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/__results__.html\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold1_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold4_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold5_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold3_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/custom.css\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold8_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold9_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold7_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold6_0.zip\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/__notebook__.ipynb\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/__output__.json\r\n",
      "/kaggle/input/final-sub-tabnet-v1-training/tabnet_raw_step1_fold0_0.zip\r\n",
      "/kaggle/input/pytorch16gpu/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl\r\n",
      "/kaggle/input/lish-moa/train_features.csv\r\n",
      "/kaggle/input/lish-moa/train_drug.csv\r\n",
      "/kaggle/input/lish-moa/test_features.csv\r\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\r\n",
      "/kaggle/input/lish-moa/sample_submission.csv\r\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\r\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.1-py3-none-any.whl\r\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-1.2.0-py3-none-any.whl\r\n",
      "/kaggle/input/iterativestratification/.gitignore\r\n",
      "/kaggle/input/iterativestratification/LICENSE\r\n",
      "/kaggle/input/iterativestratification/setup.py\r\n",
      "/kaggle/input/iterativestratification/setup.cfg\r\n",
      "/kaggle/input/iterativestratification/.travis.yml\r\n",
      "/kaggle/input/iterativestratification/README.md\r\n",
      "/kaggle/input/iterativestratification/tests/__init__.py\r\n",
      "/kaggle/input/iterativestratification/tests/test_ml_stratifiers.py\r\n",
      "/kaggle/input/iterativestratification/iterstrat/ml_stratifiers.py\r\n",
      "/kaggle/input/iterativestratification/iterstrat/__init__.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.dockerignore\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/forest_example.ipynb\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.gitatttributes\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.gitignore\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/CHANGELOG.md\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/renovate.json\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/census_example.ipynb\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/Dockerfile\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pyproject.toml\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/LICENSE\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/Makefile\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/regression_example.ipynb\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/poetry.lock\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.editorconfig\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.flake8\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/Dockerfile_gpu\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/multi_regression_example.ipynb\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/README.md\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/release-script/Dockerfile_changelog\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/release-script/do-release.sh\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/release-script/prepare-release.sh\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.github/PULL_REQUEST_TEMPLATE.md\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.github/ISSUE_TEMPLATE/bug_report.md\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.github/ISSUE_TEMPLATE/feature_request.md\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pytorch_tabnet/tab_network.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pytorch_tabnet/sparsemax.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pytorch_tabnet/multiclass_utils.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pytorch_tabnet/tab_model.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/pytorch_tabnet/utils.py\r\n",
      "/kaggle/input/tabnetdevelop/tabnet-develop/.circleci/config.yml\r\n",
      "/kaggle/input/finalsubannrankgausspcatrainingpy/Final-Sub-ANN-RankGauss-PCA-TRAINING.py\r\n",
      "/kaggle/input/iterative-stratification/iterative_stratification-0.1.6-py3-none-any.whl\r\n",
      "/kaggle/input/finalsubtabnetv1inference/final-sub-tabnet-v1-inference.py\r\n",
      "remove 0 columns\r\n",
      "remove 71 columns\r\n",
      "(21948, 874)\r\n",
      "(3982, 874)\r\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\r\n",
      "  FutureWarning)\r\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\r\n",
      "  FutureWarning)\r\n",
      "0\r\n",
      "1\r\n",
      "## SEED :  0\r\n",
      "FOLDS :  0\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 0 : 0.017789696181052844\r\n",
      "FOLDS :  1\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 1 : 0.017838912915994494\r\n",
      "FOLDS :  2\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 2 : 0.017682345672476656\r\n",
      "FOLDS :  3\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 3 : 0.017358052611545414\r\n",
      "FOLDS :  4\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 4 : 0.017978976226074948\r\n",
      "FOLDS :  5\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 5 : 0.017936706252213008\r\n",
      "FOLDS :  6\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 6 : 0.016955487434051533\r\n",
      "FOLDS :  7\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 7 : 0.01751639734296969\r\n",
      "FOLDS :  8\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 8 : 0.01692219076817177\r\n",
      "FOLDS :  9\r\n",
      "Device used : cuda\r\n",
      "Device used : cuda\r\n",
      "validation fold 9 : 0.017890024295888245\r\n",
      "CV score fold :  0.017585692541827493\r\n",
      "auc mean :  0.457787884513296\r\n",
      "[array([0.0177897 , 0.01783891, 0.01768235, 0.01735805, 0.01797898,\r\n",
      "       0.01793671, 0.01695549, 0.0175164 , 0.01692219, 0.01789002])]\r\n",
      "TabNetRegressor(cat_dims=[3, 2], cat_emb_dim=[1, 1], cat_idxs=[0, 1],\r\n",
      "                device_name='cuda', input_dim=874, lambda_sparse=0,\r\n",
      "                mask_type='entmax', n_a=24, n_d=24, n_steps=1,\r\n",
      "                optimizer_params={'lr': 0.02, 'weight_decay': 1e-05},\r\n",
      "                output_dim=206,\r\n",
      "                scheduler_params={'gamma': 0.9, 'milestones': [100, 150]})\r\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "\n",
    "#! python ../input/finalsubannrankgausspcainferencepy/final-sub-ann-rankgauss-pca-inference.py\n",
    "! python ../input/finalsubannrankgausspcatrainingpy/Final-Sub-ANN-RankGauss-PCA-TRAINING.py\n",
    "sub_ann = pd.read_csv('./submission.csv')\n",
    "! python ../input/finalsubtabnetv1inference/final-sub-tabnet-v1-inference.py\n",
    "sub_tab = pd.read_csv('./submission.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n",
    "submission = pd.DataFrame(test['sig_id'], columns=sample_submission.columns)\n",
    "submission.iloc[:, 1:] = 0\n",
    "\n",
    "submission.iloc[:, 1:] = sub_ann.iloc[:, 1:] * 0.7 + sub_tab.iloc[:, 1:] * 0.3\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T21:19:47.740807Z",
     "iopub.status.busy": "2020-11-29T21:19:47.740079Z",
     "iopub.status.idle": "2020-11-29T21:19:47.776635Z",
     "shell.execute_reply": "2020-11-29T21:19:47.777116Z"
    },
    "papermill": {
     "duration": 0.501558,
     "end_time": "2020-11-29T21:19:47.777238",
     "exception": false,
     "start_time": "2020-11-29T21:19:47.275680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.013697</td>\n",
       "      <td>0.020819</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.144034</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.002390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.025545</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.003085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.020012</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001180                0.001484   \n",
       "1     id_001897cda                     0.000881                0.001405   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001117                0.001356   \n",
       "4     id_0027f1083                     0.002036                0.002047   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001209                0.001659   \n",
       "3978  id_ff925dd0d                     0.003148                0.002200   \n",
       "3979  id_ffb710450                     0.001457                0.001526   \n",
       "3980  id_ffbb869f2                     0.001894                0.001741   \n",
       "3981  id_ffd5800b6                     0.000894                0.001384   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.003406                        0.015832   \n",
       "1           0.002581                        0.003758   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002288                        0.011174   \n",
       "4           0.001805                        0.013697   \n",
       "...              ...                             ...   \n",
       "3977        0.001180                        0.002559   \n",
       "3978        0.001449                        0.009605   \n",
       "3979        0.001560                        0.013959   \n",
       "3980        0.001719                        0.025545   \n",
       "3981        0.001588                        0.013119   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.019167                        0.004283   \n",
       "1                              0.002199                        0.002347   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.015790                        0.004455   \n",
       "4                              0.020819                        0.004153   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.008408                        0.002378   \n",
       "3978                           0.028151                        0.006282   \n",
       "3979                           0.032853                        0.004897   \n",
       "3980                           0.027687                        0.005955   \n",
       "3981                           0.020012                        0.004600   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.001922                       0.006596   \n",
       "1                       0.005329                       0.008244   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003407                       0.004122   \n",
       "4                       0.004745                       0.002485   \n",
       "...                          ...                            ...   \n",
       "3977                    0.000991                       0.002336   \n",
       "3978                    0.004910                       0.004328   \n",
       "3979                    0.002841                       0.003992   \n",
       "3980                    0.006403                       0.003875   \n",
       "3981                    0.001838                       0.004261   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000579  ...                               0.001388   \n",
       "1                       0.005466  ...                               0.001319   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000657  ...                               0.001058   \n",
       "4                       0.000852  ...                               0.001150   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000462  ...                               0.000769   \n",
       "3978                    0.001056  ...                               0.000908   \n",
       "3979                    0.000482  ...                               0.000897   \n",
       "3980                    0.000792  ...                               0.001020   \n",
       "3981                    0.000474  ...                               0.000965   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.002007         0.004713           0.001446   \n",
       "1         0.001503         0.006066           0.000685   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001940         0.003520           0.014808   \n",
       "4         0.000986         0.002750           0.001520   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005867         0.002022           0.144034   \n",
       "3978      0.001396         0.003603           0.002348   \n",
       "3979      0.001117         0.003626           0.002390   \n",
       "3980      0.000933         0.003230           0.001403   \n",
       "3981      0.001815         0.002511           0.004442   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001108                               0.000973   \n",
       "1                      0.012025                               0.000949   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.006208                               0.000979   \n",
       "4                      0.002064                               0.000963   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.007371                               0.001205   \n",
       "3978                   0.003412                               0.000927   \n",
       "3979                   0.001920                               0.000835   \n",
       "3980                   0.002783                               0.000853   \n",
       "3981                   0.001960                               0.000934   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001309   0.002139                    0.007062       0.002059  \n",
       "1            0.007674   0.001539                    0.001159       0.004015  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002367   0.002284                    0.000770       0.002476  \n",
       "4            0.002036   0.002157                    0.000568       0.002374  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.007343   0.001340                    0.000665       0.001202  \n",
       "3978         0.002828   0.002026                    0.000750       0.002390  \n",
       "3979         0.001457   0.001838                    0.000787       0.001519  \n",
       "3980         0.001327   0.002320                    0.000756       0.003085  \n",
       "3981         0.001189   0.002171                    0.000787       0.001798  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ann "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T21:19:48.686272Z",
     "iopub.status.busy": "2020-11-29T21:19:48.685608Z",
     "iopub.status.idle": "2020-11-29T21:19:48.720328Z",
     "shell.execute_reply": "2020-11-29T21:19:48.719394Z"
    },
    "papermill": {
     "duration": 0.488571,
     "end_time": "2020-11-29T21:19:48.720576",
     "exception": false,
     "start_time": "2020-11-29T21:19:48.232005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.068274</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>0.025786</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001429                0.001775   \n",
       "1     id_001897cda                     0.000937                0.001483   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001309                0.001528   \n",
       "4     id_0027f1083                     0.001538                0.001835   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001182                0.002018   \n",
       "3978  id_ff925dd0d                     0.001651                0.001879   \n",
       "3979  id_ffb710450                     0.001455                0.001615   \n",
       "3980  id_ffbb869f2                     0.001345                0.001537   \n",
       "3981  id_ffd5800b6                     0.001235                0.001605   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001839                        0.013926   \n",
       "1           0.002378                        0.003358   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.001906                        0.009603   \n",
       "4           0.001876                        0.012960   \n",
       "...              ...                             ...   \n",
       "3977        0.002274                        0.005093   \n",
       "3978        0.001799                        0.010741   \n",
       "3979        0.001696                        0.012306   \n",
       "3980        0.001741                        0.016477   \n",
       "3981        0.001836                        0.014265   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.028678                        0.005915   \n",
       "1                              0.002729                        0.002620   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.019103                        0.005117   \n",
       "4                              0.022519                        0.005531   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.010663                        0.003721   \n",
       "3978                           0.024745                        0.005766   \n",
       "3979                           0.032964                        0.006039   \n",
       "3980                           0.023147                        0.005489   \n",
       "3981                           0.025786                        0.005467   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002981                       0.003989   \n",
       "1                       0.002373                       0.010238   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003016                       0.004654   \n",
       "4                       0.004015                       0.002880   \n",
       "...                          ...                            ...   \n",
       "3977                    0.002446                       0.004565   \n",
       "3978                    0.004356                       0.003761   \n",
       "3979                    0.002944                       0.004086   \n",
       "3980                    0.004152                       0.003647   \n",
       "3981                    0.002922                       0.004457   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000665  ...                               0.000969   \n",
       "1                       0.001923  ...                               0.001214   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000783  ...                               0.000939   \n",
       "4                       0.000924  ...                               0.000975   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000970  ...                               0.001148   \n",
       "3978                    0.001101  ...                               0.000937   \n",
       "3979                    0.000552  ...                               0.000868   \n",
       "3980                    0.000920  ...                               0.000990   \n",
       "3981                    0.000602  ...                               0.000986   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.000986         0.003194           0.001616   \n",
       "1         0.002010         0.005936           0.001059   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001744         0.002886           0.007298   \n",
       "4         0.000967         0.003232           0.002085   \n",
       "...            ...              ...                ...   \n",
       "3977      0.003078         0.003694           0.068274   \n",
       "3978      0.000878         0.004006           0.001177   \n",
       "3979      0.000907         0.002955           0.002245   \n",
       "3980      0.000829         0.002765           0.001449   \n",
       "3981      0.001438         0.002907           0.002803   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001232                               0.001014   \n",
       "1                      0.006581                               0.001095   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.004699                               0.001080   \n",
       "4                      0.001293                               0.001025   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.009520                               0.001478   \n",
       "3978                   0.001757                               0.001065   \n",
       "3979                   0.001471                               0.000941   \n",
       "3980                   0.001579                               0.000933   \n",
       "3981                   0.001932                               0.000997   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.000878   0.002245                    0.001751       0.002029  \n",
       "1            0.005469   0.002115                    0.012690       0.003425  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.001784   0.002310                    0.000953       0.002234  \n",
       "4            0.001124   0.002168                    0.000806       0.002094  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004169   0.002028                    0.001179       0.001758  \n",
       "3978         0.002404   0.002187                    0.000674       0.002126  \n",
       "3979         0.001163   0.002186                    0.001179       0.001876  \n",
       "3980         0.001144   0.002290                    0.001158       0.002364  \n",
       "3981         0.001014   0.002197                    0.001122       0.002042  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T21:19:49.668279Z",
     "iopub.status.busy": "2020-11-29T21:19:49.667362Z",
     "iopub.status.idle": "2020-11-29T21:19:49.695746Z",
     "shell.execute_reply": "2020-11-29T21:19:49.696209Z"
    },
    "papermill": {
     "duration": 0.482455,
     "end_time": "2020-11-29T21:19:49.696324",
     "exception": false,
     "start_time": "2020-11-29T21:19:49.213869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.0012544</td>\n",
       "      <td>0.0015716</td>\n",
       "      <td>0.00293561</td>\n",
       "      <td>0.0152604</td>\n",
       "      <td>0.0220201</td>\n",
       "      <td>0.0047729</td>\n",
       "      <td>0.00223928</td>\n",
       "      <td>0.00581352</td>\n",
       "      <td>0.000604539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00126237</td>\n",
       "      <td>0.0017009</td>\n",
       "      <td>0.00425745</td>\n",
       "      <td>0.00149676</td>\n",
       "      <td>0.00114546</td>\n",
       "      <td>0.000985331</td>\n",
       "      <td>0.0011796</td>\n",
       "      <td>0.00217044</td>\n",
       "      <td>0.00546882</td>\n",
       "      <td>0.00204987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000897999</td>\n",
       "      <td>0.00142874</td>\n",
       "      <td>0.00252007</td>\n",
       "      <td>0.00363816</td>\n",
       "      <td>0.00235809</td>\n",
       "      <td>0.00242886</td>\n",
       "      <td>0.00444223</td>\n",
       "      <td>0.00884245</td>\n",
       "      <td>0.0044028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0012879</td>\n",
       "      <td>0.00165501</td>\n",
       "      <td>0.0060273</td>\n",
       "      <td>0.000797511</td>\n",
       "      <td>0.0103916</td>\n",
       "      <td>0.000992779</td>\n",
       "      <td>0.00701276</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.00461825</td>\n",
       "      <td>0.00383836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.00117456</td>\n",
       "      <td>0.00140787</td>\n",
       "      <td>0.00217316</td>\n",
       "      <td>0.0107025</td>\n",
       "      <td>0.0167837</td>\n",
       "      <td>0.00465357</td>\n",
       "      <td>0.0032898</td>\n",
       "      <td>0.00428174</td>\n",
       "      <td>0.000694542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00102252</td>\n",
       "      <td>0.00188168</td>\n",
       "      <td>0.00332978</td>\n",
       "      <td>0.0125547</td>\n",
       "      <td>0.00575512</td>\n",
       "      <td>0.00100972</td>\n",
       "      <td>0.00219185</td>\n",
       "      <td>0.00229217</td>\n",
       "      <td>0.000824606</td>\n",
       "      <td>0.00240324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.0018868</td>\n",
       "      <td>0.00198373</td>\n",
       "      <td>0.00182604</td>\n",
       "      <td>0.0134759</td>\n",
       "      <td>0.0213292</td>\n",
       "      <td>0.00456649</td>\n",
       "      <td>0.00452578</td>\n",
       "      <td>0.00260321</td>\n",
       "      <td>0.000873881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00109728</td>\n",
       "      <td>0.000980141</td>\n",
       "      <td>0.00289456</td>\n",
       "      <td>0.00168941</td>\n",
       "      <td>0.00183275</td>\n",
       "      <td>0.000981833</td>\n",
       "      <td>0.00176222</td>\n",
       "      <td>0.00216008</td>\n",
       "      <td>0.000639079</td>\n",
       "      <td>0.00228997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.00120101</td>\n",
       "      <td>0.0017668</td>\n",
       "      <td>0.0015081</td>\n",
       "      <td>0.00331943</td>\n",
       "      <td>0.00908427</td>\n",
       "      <td>0.00278101</td>\n",
       "      <td>0.00142721</td>\n",
       "      <td>0.00300437</td>\n",
       "      <td>0.000614603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000882451</td>\n",
       "      <td>0.00503038</td>\n",
       "      <td>0.00252345</td>\n",
       "      <td>0.121306</td>\n",
       "      <td>0.00801603</td>\n",
       "      <td>0.00128706</td>\n",
       "      <td>0.00639074</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000819084</td>\n",
       "      <td>0.00136847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.00269909</td>\n",
       "      <td>0.00210405</td>\n",
       "      <td>0.00155394</td>\n",
       "      <td>0.00994576</td>\n",
       "      <td>0.0271294</td>\n",
       "      <td>0.00612754</td>\n",
       "      <td>0.00474405</td>\n",
       "      <td>0.00415799</td>\n",
       "      <td>0.0010693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000916832</td>\n",
       "      <td>0.00124097</td>\n",
       "      <td>0.00372355</td>\n",
       "      <td>0.0019965</td>\n",
       "      <td>0.00291508</td>\n",
       "      <td>0.000968716</td>\n",
       "      <td>0.0027009</td>\n",
       "      <td>0.00207446</td>\n",
       "      <td>0.000727069</td>\n",
       "      <td>0.00231125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.00145595</td>\n",
       "      <td>0.00155296</td>\n",
       "      <td>0.00160073</td>\n",
       "      <td>0.0134628</td>\n",
       "      <td>0.0328862</td>\n",
       "      <td>0.00523944</td>\n",
       "      <td>0.00287214</td>\n",
       "      <td>0.00402005</td>\n",
       "      <td>0.000503305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000888046</td>\n",
       "      <td>0.00105424</td>\n",
       "      <td>0.00342441</td>\n",
       "      <td>0.00234659</td>\n",
       "      <td>0.00178526</td>\n",
       "      <td>0.000866785</td>\n",
       "      <td>0.00136895</td>\n",
       "      <td>0.00194217</td>\n",
       "      <td>0.000904235</td>\n",
       "      <td>0.00162591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.00172945</td>\n",
       "      <td>0.00167997</td>\n",
       "      <td>0.00172545</td>\n",
       "      <td>0.0228248</td>\n",
       "      <td>0.0263247</td>\n",
       "      <td>0.00581493</td>\n",
       "      <td>0.00572738</td>\n",
       "      <td>0.00380658</td>\n",
       "      <td>0.000830574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00101106</td>\n",
       "      <td>0.000902102</td>\n",
       "      <td>0.0030908</td>\n",
       "      <td>0.00141679</td>\n",
       "      <td>0.00242149</td>\n",
       "      <td>0.000877388</td>\n",
       "      <td>0.00127197</td>\n",
       "      <td>0.00231087</td>\n",
       "      <td>0.000876688</td>\n",
       "      <td>0.00286828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000996487</td>\n",
       "      <td>0.00145063</td>\n",
       "      <td>0.00166214</td>\n",
       "      <td>0.0134628</td>\n",
       "      <td>0.0217443</td>\n",
       "      <td>0.00485992</td>\n",
       "      <td>0.00216336</td>\n",
       "      <td>0.00432004</td>\n",
       "      <td>0.000512655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000971471</td>\n",
       "      <td>0.00170205</td>\n",
       "      <td>0.00262982</td>\n",
       "      <td>0.00395052</td>\n",
       "      <td>0.00195192</td>\n",
       "      <td>0.000953235</td>\n",
       "      <td>0.00113612</td>\n",
       "      <td>0.00217877</td>\n",
       "      <td>0.000887278</td>\n",
       "      <td>0.00187136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id 5-alpha_reductase_inhibitor 11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                   0.0012544              0.0015716   \n",
       "1     id_001897cda                 0.000897999             0.00142874   \n",
       "2     id_002429b5b                           0                      0   \n",
       "3     id_00276f245                  0.00117456             0.00140787   \n",
       "4     id_0027f1083                   0.0018868             0.00198373   \n",
       "...            ...                         ...                    ...   \n",
       "3977  id_ff7004b87                  0.00120101              0.0017668   \n",
       "3978  id_ff925dd0d                  0.00269909             0.00210405   \n",
       "3979  id_ffb710450                  0.00145595             0.00155296   \n",
       "3980  id_ffbb869f2                  0.00172945             0.00167997   \n",
       "3981  id_ffd5800b6                 0.000996487             0.00145063   \n",
       "\n",
       "     acat_inhibitor acetylcholine_receptor_agonist  \\\n",
       "0        0.00293561                      0.0152604   \n",
       "1        0.00252007                     0.00363816   \n",
       "2                 0                              0   \n",
       "3        0.00217316                      0.0107025   \n",
       "4        0.00182604                      0.0134759   \n",
       "...             ...                            ...   \n",
       "3977      0.0015081                     0.00331943   \n",
       "3978     0.00155394                     0.00994576   \n",
       "3979     0.00160073                      0.0134628   \n",
       "3980     0.00172545                      0.0228248   \n",
       "3981     0.00166214                      0.0134628   \n",
       "\n",
       "     acetylcholine_receptor_antagonist acetylcholinesterase_inhibitor  \\\n",
       "0                            0.0220201                      0.0047729   \n",
       "1                           0.00235809                     0.00242886   \n",
       "2                                    0                              0   \n",
       "3                            0.0167837                     0.00465357   \n",
       "4                            0.0213292                     0.00456649   \n",
       "...                                ...                            ...   \n",
       "3977                        0.00908427                     0.00278101   \n",
       "3978                         0.0271294                     0.00612754   \n",
       "3979                         0.0328862                     0.00523944   \n",
       "3980                         0.0263247                     0.00581493   \n",
       "3981                         0.0217443                     0.00485992   \n",
       "\n",
       "     adenosine_receptor_agonist adenosine_receptor_antagonist  \\\n",
       "0                    0.00223928                    0.00581352   \n",
       "1                    0.00444223                    0.00884245   \n",
       "2                             0                             0   \n",
       "3                     0.0032898                    0.00428174   \n",
       "4                    0.00452578                    0.00260321   \n",
       "...                         ...                           ...   \n",
       "3977                 0.00142721                    0.00300437   \n",
       "3978                 0.00474405                    0.00415799   \n",
       "3979                 0.00287214                    0.00402005   \n",
       "3980                 0.00572738                    0.00380658   \n",
       "3981                 0.00216336                    0.00432004   \n",
       "\n",
       "     adenylyl_cyclase_activator  ... tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                   0.000604539  ...                            0.00126237   \n",
       "1                     0.0044028  ...                             0.0012879   \n",
       "2                             0  ...                                     0   \n",
       "3                   0.000694542  ...                            0.00102252   \n",
       "4                   0.000873881  ...                            0.00109728   \n",
       "...                         ...  ...                                   ...   \n",
       "3977                0.000614603  ...                           0.000882451   \n",
       "3978                  0.0010693  ...                           0.000916832   \n",
       "3979                0.000503305  ...                           0.000888046   \n",
       "3980                0.000830574  ...                            0.00101106   \n",
       "3981                0.000512655  ...                           0.000971471   \n",
       "\n",
       "     trpv_agonist trpv_antagonist tubulin_inhibitor tyrosine_kinase_inhibitor  \\\n",
       "0       0.0017009      0.00425745        0.00149676                0.00114546   \n",
       "1      0.00165501       0.0060273       0.000797511                 0.0103916   \n",
       "2               0               0                 0                         0   \n",
       "3      0.00188168      0.00332978         0.0125547                0.00575512   \n",
       "4     0.000980141      0.00289456        0.00168941                0.00183275   \n",
       "...           ...             ...               ...                       ...   \n",
       "3977   0.00503038      0.00252345          0.121306                0.00801603   \n",
       "3978   0.00124097      0.00372355         0.0019965                0.00291508   \n",
       "3979   0.00105424      0.00342441        0.00234659                0.00178526   \n",
       "3980  0.000902102       0.0030908        0.00141679                0.00242149   \n",
       "3981   0.00170205      0.00262982        0.00395052                0.00195192   \n",
       "\n",
       "     ubiquitin_specific_protease_inhibitor vegfr_inhibitor   vitamin_b  \\\n",
       "0                              0.000985331       0.0011796  0.00217044   \n",
       "1                              0.000992779      0.00701276    0.001712   \n",
       "2                                        0               0           0   \n",
       "3                               0.00100972      0.00219185  0.00229217   \n",
       "4                              0.000981833      0.00176222  0.00216008   \n",
       "...                                    ...             ...         ...   \n",
       "3977                            0.00128706      0.00639074    0.001546   \n",
       "3978                           0.000968716       0.0027009  0.00207446   \n",
       "3979                           0.000866785      0.00136895  0.00194217   \n",
       "3980                           0.000877388      0.00127197  0.00231087   \n",
       "3981                           0.000953235      0.00113612  0.00217877   \n",
       "\n",
       "     vitamin_d_receptor_agonist wnt_inhibitor  \n",
       "0                    0.00546882    0.00204987  \n",
       "1                    0.00461825    0.00383836  \n",
       "2                             0             0  \n",
       "3                   0.000824606    0.00240324  \n",
       "4                   0.000639079    0.00228997  \n",
       "...                         ...           ...  \n",
       "3977                0.000819084    0.00136847  \n",
       "3978                0.000727069    0.00231125  \n",
       "3979                0.000904235    0.00162591  \n",
       "3980                0.000876688    0.00286828  \n",
       "3981                0.000887278    0.00187136  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1282.225774,
   "end_time": "2020-11-29T21:19:50.248131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-29T20:58:28.022357",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
